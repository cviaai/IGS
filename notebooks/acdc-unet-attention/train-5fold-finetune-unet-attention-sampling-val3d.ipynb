{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "import sys\n",
    "sys.path.append('/home/a_razumov/projects/k-space-mri')\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from k_space_reconstruction.utils.metrics import pt_msssim, pt_ssim\n",
    "from k_space_reconstruction.datasets.acdc import ACDCSet, ACDCTransform, RandomMaskFunc\n",
    "from k_space_reconstruction.datasets.fastmri import FastMRIh5Dataset, FastMRITransform, LegacyFastMRIh5Dataset\n",
    "from k_space_reconstruction.utils.kspace import EquispacedMaskFunc, RandomMaskFunc\n",
    "from k_space_reconstruction.utils.kspace import pt_spatial2kspace as Ft\n",
    "from k_space_reconstruction.utils.kspace import pt_kspace2spatial as IFt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from k_space_reconstruction.nets.unet import Unet\n",
    "from k_space_reconstruction.nets.enet import ENet\n",
    "from k_space_reconstruction.nets.mwcnn import MWCNN\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "plt.style.use('bmh')\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pylab as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os.path import isdir, join\n",
    "from typing import Callable, Dict, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_bezzeless = lambda nc, nr : plt.subplots(ncols=nc, nrows=nr, figsize=(4 * nc, 4), dpi=120, \n",
    "                                             subplot_kw=dict(frameon=False, xticks=[], yticks=[]), \n",
    "                                             gridspec_kw=dict(wspace=0.0, hspace=0.0))\n",
    "\n",
    "\n",
    "def ce_loss(true, logits, weights, ignore=255):\n",
    "    torch.nn.CrossEntropyLoss\n",
    "    ce_loss = torch.nn.functional.cross_entropy(\n",
    "        logits.float(),\n",
    "        true.long(),\n",
    "        ignore_index=ignore,\n",
    "        weight=weights,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = torch.nn.functional.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "def dice_coeffs(true, logits):\n",
    "    num_classes = logits.shape[1]\n",
    "    probas = F.softmax(logits, dim=1)\n",
    "    probas[probas > 0.5] = 1; probas[probas <= 0.5] = 0\n",
    "    pmask = torch.zeros_like(true).float()\n",
    "    for i in range(1, num_classes):\n",
    "        pmask[:,0] += i * probas[:,i]\n",
    "    dice_ls = []\n",
    "    for i in range(1, num_classes):\n",
    "        yt = (true==i).float().flatten()\n",
    "        yp = (pmask==i).float().flatten()\n",
    "        intersection = torch.sum(yt * yp)\n",
    "        cardinality = torch.sum(yt + yp)\n",
    "        dice_ls.append((2. * intersection / (cardinality + 1e-7)).item())\n",
    "    return dice_ls   \n",
    "\n",
    "def finetune_model_on_sampling(train_generator, model, sampling, epochs=5, return_losses=False):\n",
    "    if not os.path.exists('acdc_unet_checkpoints'):\n",
    "        os.makedirs('acdc_unet_checkpoints')\n",
    "    losses = np.zeros(epochs)\n",
    "    checkpoints = []\n",
    "    criterion = lambda p,t : dice_loss(t, p) * .75 + ce_loss(t.squeeze(1), p, weights=None) * .25\n",
    "    metric = lambda p,t : 1 - dice_loss(t, p)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        model = model.train()\n",
    "        for _, targets, images, means, stds in train_generator:\n",
    "            images = images.cuda(); targets = targets.cuda().long(); means = means.cuda(); stds = stds.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            # backpropagate\n",
    "            images = (IFt(Ft(images * stds + means) * sampling).abs() - means) / (stds + 1e-11)\n",
    "            pred = model(images)\n",
    "            loss = criterion(pred, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses[epoch] += loss.item() / len(train_generator)\n",
    "        model = model.train(False).eval()\n",
    "        checkpoint_path = join('acdc_unet_checkpoints', 'epoch%d.pth' % epoch)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        checkpoints.append(checkpoint_path)\n",
    "    del optimizer\n",
    "    best_checkpoint = checkpoints[np.argmin(losses)]\n",
    "    model.load_state_dict(torch.load(best_checkpoint))\n",
    "    if return_losses:\n",
    "        return model, losses\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "def train_sampling_pattern(train_generator, model, n=14):\n",
    "    c, bmasks, images, bmean, bstd = next(iter(train_generator))\n",
    "    bks = Ft(images * bstd + bmean)\n",
    "    bgt = IFt(bks).abs()\n",
    "    w = torch.zeros(256).cuda().float()\n",
    "    w[128] = 1\n",
    "    bbatch = 32\n",
    "    w_list = []\n",
    "    pbar = tqdm(range(n))\n",
    "    for count in pbar:\n",
    "        w = torch.autograd.Variable(w, requires_grad=True)\n",
    "        for j in range(bks.shape[0] // bbatch):\n",
    "            bbks = bks[bbatch*j:bbatch*(j+1)].cuda()\n",
    "            bbgt = bgt[bbatch*j:bbatch*(j+1)].cuda()\n",
    "            bbmean = bmean[bbatch*j:bbatch*(j+1)].cuda()\n",
    "            bbstd = bstd[bbatch*j:bbatch*(j+1)].cuda()\n",
    "            bbmasks = bmasks[bbatch*j:bbatch*(j+1)].cuda()\n",
    "            recs = IFt(bbks * w).abs()\n",
    "            pm = model((recs - bbmean) / (bbstd + 1e-11))\n",
    "            loss = dice_loss(bbmasks.long(), pm)\n",
    "            loss.backward()\n",
    "        for i in torch.topk(w.grad, 256, largest=False).indices:\n",
    "            if w[i] == 0: \n",
    "                w = w.detach()\n",
    "                w[i] = 1.\n",
    "                w_list.append(w.clone())\n",
    "                pbar.set_description('select: %d, loss: %.6f' % (i.item(), loss.item()))\n",
    "                break\n",
    "    return w_list\n",
    "\n",
    "def test_sampling_pattern(sampling, model, val_generator):\n",
    "    vc, vbmasks, vimages, vbmean, vbstd = next(iter(val_generator))\n",
    "    vbks = Ft(vimages * vbstd + vbmean)\n",
    "    vbgt = IFt(vbks).abs()\n",
    "    dice_scores = []\n",
    "    bbatch = 32\n",
    "    for j in tqdm(range(vbks.shape[0] // bbatch)):\n",
    "        vbbks = vbks[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbgt = vbgt[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbmean = vbmean[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbstd = vbstd[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbmasks = vbmasks[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        with torch.no_grad():\n",
    "            # igs\n",
    "            recs = IFt(vbbks * sampling).abs()\n",
    "            pm = model((recs - vbbmean) / (vbbstd + 1e-11))\n",
    "            for i in range(recs.shape[0]):\n",
    "                dice_scores.append(1 - dice_loss(vbbmasks.long(), pm).item())\n",
    "    return dice_scores\n",
    "\n",
    "def test_on_classes_sampling_pattern(sampling, model, val_generator):\n",
    "    vc, vbmasks, vimages, vbmean, vbstd = next(iter(val_generator))\n",
    "    vbks = Ft(vimages * vbstd + vbmean)\n",
    "    vbgt = IFt(vbks).abs()\n",
    "    dice_scores = []\n",
    "    bbatch = 1\n",
    "    for j in tqdm(range(vbks.shape[0] // bbatch)):\n",
    "        vbbks = vbks[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbgt = vbgt[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbmean = vbmean[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbstd = vbstd[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        vbbmasks = vbmasks[bbatch*j:bbatch*(j+1)].cuda()\n",
    "        with torch.no_grad():\n",
    "            # igs\n",
    "            recs = IFt(vbbks * sampling).abs()\n",
    "            pm = model((recs - vbbmean) / (vbbstd + 1e-11))\n",
    "            for i in range(recs.shape[0]):\n",
    "                dice_scores.append(dice_coeffs(vbbmasks.long(), pm))\n",
    "    return dice_scores\n",
    "\n",
    "class ACDCDataset(torch.utils.data.Dataset):\n",
    "    CLASSES = {0: 'NOR', 1: 'MINF', 2: 'DCM', 3: 'HCM', 4: 'RV'}\n",
    "\n",
    "    def __init__(self, hf_path: str):\n",
    "        super().__init__()\n",
    "        self.hf = h5py.File(hf_path)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.hf)\n",
    "\n",
    "    def __getitem__(self, item: int):\n",
    "        img = self.hf[str(item)][:1]\n",
    "        mask = self.hf[str(item)][1:]\n",
    "        c = self.hf[str(item)].attrs['class']\n",
    "        img = torch.tensor(img).float()\n",
    "        mask = torch.tensor(mask)\n",
    "        mean = img.mean()\n",
    "        std = img.std()\n",
    "        img = (img - mean) / (std + 1e-11)\n",
    "        return c, mask, img, mean.unsqueeze(0).unsqueeze(0).unsqueeze(0), std.unsqueeze(0).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_psnr(img1, img2, maxval):\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    return 20 * torch.log10(maxval / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ACDCDataset('/home/a_razumov/small_datasets/acdc_seg_h5/train.h5')\n",
    "val_dataset = ACDCDataset('/home/a_razumov/small_datasets/acdc_seg_h5/val.h5')\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True, num_workers=6)\n",
    "val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from network import AttU_Net\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model.load_state_dict(torch.load('unet-attention-32.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval dice classes scores x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708ad3df0c6143f493eeb00ec619c1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=514.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd50489dec045fbbe5665324eb4f769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=514.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e97da53d234a3f9d24738efc4058f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=514.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaf25d0ec144259ab29ae1ba4dfb18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=514.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## fastmri ##############\n",
      "        RV cavity      LV myo   LV cavity\n",
      "count  514.000000  514.000000  514.000000\n",
      "mean     0.529792    0.595712    0.696303\n",
      "std      0.368311    0.259475    0.328479\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.465431    0.638327\n",
      "50%      0.707511    0.704947    0.855576\n",
      "75%      0.846951    0.782964    0.917861\n",
      "max      0.958165    0.908544    0.976233\n",
      "############## center ##############\n",
      "        RV cavity      LV myo   LV cavity\n",
      "count  514.000000  514.000000  514.000000\n",
      "mean     0.622126    0.671036    0.769905\n",
      "std      0.371518    0.255826    0.310312\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.266411    0.598950    0.809087\n",
      "50%      0.823540    0.773983    0.908627\n",
      "75%      0.899477    0.834859    0.943581\n",
      "max      0.969189    0.928571    0.979793\n",
      "############## ours ##############\n",
      "        RV cavity      LV myo   LV cavity\n",
      "count  514.000000  514.000000  514.000000\n",
      "mean     0.620267    0.702600    0.784465\n",
      "std      0.373181    0.227744    0.290620\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.222238    0.665104    0.828611\n",
      "50%      0.822891    0.788835    0.903742\n",
      "75%      0.901212    0.845243    0.943512\n",
      "max      0.963052    0.930965    0.981141\n",
      "############## full ##############\n",
      "        RV cavity      LV myo   LV cavity\n",
      "count  514.000000  514.000000  514.000000\n",
      "mean     0.750605    0.848891    0.877192\n",
      "std      0.348477    0.176874    0.231204\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.804193    0.854808    0.917783\n",
      "50%      0.922832    0.896988    0.954770\n",
      "75%      0.954148    0.925525    0.973237\n",
      "max      0.983710    0.965732    0.991408\n"
     ]
    }
   ],
   "source": [
    "fastmri_mask_x16 = torch.tensor(EquispacedMaskFunc([0.04], [16])((256, 256))[0]).cuda().float()\n",
    "zm = torch.zeros(256).cuda().float()\n",
    "zm[256//2 - int(16)//2 : 256//2 + int(16)//2] = 1\n",
    "fm = torch.ones(256).cuda().float()\n",
    "w = torch.load('sampling_igs_finetune.pt')\n",
    "\n",
    "model = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model.load_state_dict(torch.load('unet-attention-32.pt'))\n",
    "model_zm = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model_zm.load_state_dict(torch.load('model_zm.pt'))\n",
    "model_igs = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model_igs.load_state_dict(torch.load('model_igs.pt'))\n",
    "model_fastmri = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model_fastmri.load_state_dict(torch.load('model_fastmri.pt'))\n",
    "\n",
    "dice_class_scores = dict(\n",
    "    fastmri=test_on_classes_sampling_pattern(fastmri_mask_x16, model_fastmri, val_generator), \n",
    "    center=test_on_classes_sampling_pattern(zm, model_zm, val_generator),\n",
    "    ours=test_on_classes_sampling_pattern(w, model_igs, val_generator),\n",
    "    full=test_on_classes_sampling_pattern(fm, model, val_generator),\n",
    ")\n",
    "\n",
    "class_map = {0: 'RV cavity', 1: 'LV myo', 2: 'LV cavity'}\n",
    "for name in dice_class_scores.keys():\n",
    "    arr = np.array(dice_class_scores[name]).T\n",
    "    print('##############', name, '##############')\n",
    "    print(pd.DataFrame.from_dict({class_map[i]:arr[i] for i in range(arr.shape[0])}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_3d_classes(true, logits, eps=1e-11):\n",
    "    num_classes = logits.shape[0]\n",
    "    probas = torch.nn.functional.softmax(logits, dim=0)\n",
    "    probas[probas > 0.5] = 1\n",
    "    probas[probas <= 0.5] = 0\n",
    "    pmask = torch.zeros_like(true).float()\n",
    "    for i in range(1, num_classes): pmask[0] += probas[i] * i\n",
    "    dice_ls = []\n",
    "    # WT\n",
    "    true_1_hot = (true==1).float().flatten()\n",
    "    pred_1_hot = (pmask==1).float().flatten()\n",
    "    intersection = torch.sum(pred_1_hot * true_1_hot)\n",
    "    cardinality = torch.sum(pred_1_hot + true_1_hot)\n",
    "    dice_ls.append((2. * intersection / (cardinality + eps)).item())\n",
    "    # ET\n",
    "    true_1_hot = (true==2).float().flatten()\n",
    "    pred_1_hot = (pmask==2).float().flatten()\n",
    "    intersection = torch.sum(pred_1_hot * true_1_hot)\n",
    "    cardinality = torch.sum(pred_1_hot + true_1_hot)\n",
    "    dice_ls.append((2. * intersection / (cardinality + eps)).item())\n",
    "    # TC\n",
    "    true_1_hot = (true==3).float().flatten()\n",
    "    pred_1_hot = (pmask==3).float().flatten()\n",
    "    intersection = torch.sum(pred_1_hot * true_1_hot)\n",
    "    cardinality = torch.sum(pred_1_hot + true_1_hot)\n",
    "    dice_ls.append((2. * intersection / (cardinality + eps)).item())\n",
    "    return dice_ls\n",
    "\n",
    "def test_3d_on_classes_sampling_pattern(sampling, model, val_3d_dataset):\n",
    "    dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(val_3d_dataset))):\n",
    "            _, mask, img, mean, std = val_3d_dataset[i]\n",
    "            mask = mask.cuda(); img = img.cuda(); mean = mean.cuda(); std = std.cuda()\n",
    "            ks = Ft(img * std + mean)\n",
    "            img = (IFt(ks * sampling).abs() - mean) / (std + 1e-11)\n",
    "            pred = model(img.movedim(1,0))\n",
    "            dice_scores.append(dice_coeff_3d_classes(mask, pred.movedim(1,0)))\n",
    "    return dice_scores\n",
    "\n",
    "class ACDCDataset3D(torch.utils.data.Dataset):\n",
    "    CLASSES = {0: 'NOR', 1: 'MINF', 2: 'DCM', 3: 'HCM', 4: 'RV'}\n",
    "\n",
    "    def __init__(self, hf_path: str):\n",
    "        super().__init__()\n",
    "        self.hf = h5py.File(hf_path)\n",
    "        self.vols = []\n",
    "        for k in self.hf.keys():\n",
    "            for kk in self.hf[k].keys():\n",
    "                self.vols.append((k, kk))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vols)\n",
    "\n",
    "    def __getitem__(self, item: int):\n",
    "        k, kk = self.vols[item]\n",
    "        vol = self.hf[k][kk][:1]\n",
    "        mask = self.hf[k][kk][1:]\n",
    "        \n",
    "        vol = torch.tensor(vol).float()\n",
    "        mask = torch.tensor(mask)\n",
    "        mean = vol.mean()\n",
    "        std = vol.std()\n",
    "        vol = (vol - mean) / (std + 1e-11)\n",
    "        return _, mask, vol, mean.unsqueeze(0).unsqueeze(0).unsqueeze(0), std.unsqueeze(0).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ACDCDataset3D('/home/a_razumov/small_datasets/acdc_seg_h5/val_3d.h5')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc4fd3b46a74880b7522a7dcd563f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b85893e73049329753f33ffdc4917b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d104bb37f243bdbc197187052ac5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91467f274caa424bad55d962aedff014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## fastmri ##############\n",
      "       RV cavity     LV myo  LV cavity\n",
      "count  60.000000  60.000000  60.000000\n",
      "mean    0.691694   0.638306   0.783038\n",
      "std     0.201918   0.154715   0.182845\n",
      "min     0.000000   0.128575   0.000000\n",
      "25%     0.627757   0.624429   0.756130\n",
      "50%     0.779616   0.700918   0.821641\n",
      "75%     0.826688   0.738252   0.884002\n",
      "max     0.884003   0.800890   0.935637\n",
      "############## center ##############\n",
      "       RV cavity     LV myo  LV cavity\n",
      "count  60.000000  60.000000  60.000000\n",
      "mean    0.795121   0.727285   0.851284\n",
      "std     0.147554   0.121474   0.155944\n",
      "min     0.000000   0.131117   0.000000\n",
      "25%     0.748617   0.712566   0.842919\n",
      "50%     0.837361   0.753287   0.894589\n",
      "75%     0.881364   0.806803   0.927536\n",
      "max     0.928996   0.860614   0.966750\n",
      "############## ours ##############\n",
      "       RV cavity     LV myo  LV cavity\n",
      "count  60.000000  60.000000  60.000000\n",
      "mean    0.789742   0.749433   0.859025\n",
      "std     0.142021   0.095229   0.141937\n",
      "min     0.214559   0.362475   0.043602\n",
      "25%     0.734230   0.721260   0.858721\n",
      "50%     0.837160   0.772680   0.893197\n",
      "75%     0.886448   0.807898   0.932827\n",
      "max     0.934624   0.885903   0.970144\n",
      "############## full ##############\n",
      "       RV cavity     LV myo  LV cavity\n",
      "count  60.000000  60.000000  60.000000\n",
      "mean    0.898951   0.890700   0.941496\n",
      "std     0.075434   0.033607   0.066725\n",
      "min     0.513483   0.793838   0.483936\n",
      "25%     0.875486   0.876731   0.934316\n",
      "50%     0.918714   0.895336   0.957000\n",
      "75%     0.948329   0.913566   0.970693\n",
      "max     0.970107   0.945955   0.984670\n"
     ]
    }
   ],
   "source": [
    "fastmri_mask_x16 = torch.tensor(EquispacedMaskFunc([0.04], [16])((256, 256))[0]).cuda().float()\n",
    "zm = torch.zeros(256).cuda().float()\n",
    "zm[256//2 - int(16)//2 : 256//2 + int(16)//2] = 1\n",
    "fm = torch.ones(256).cuda().float()\n",
    "w = torch.load('sampling_igs_finetune.pt')\n",
    "\n",
    "model = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model.load_state_dict(torch.load('unet-attention-32.pt'))\n",
    "model_zm = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model_zm.load_state_dict(torch.load('model_zm.pt'))\n",
    "model_igs = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model_igs.load_state_dict(torch.load('model_igs.pt'))\n",
    "model_fastmri = AttU_Net(1, 3+1, 32).to(device).train(False).eval()\n",
    "model_fastmri.load_state_dict(torch.load('model_fastmri.pt'))\n",
    "\n",
    "dice_class_scores = dict(\n",
    "    fastmri=test_3d_on_classes_sampling_pattern(fastmri_mask_x16, model_fastmri, dataset), \n",
    "    center=test_3d_on_classes_sampling_pattern(zm, model_zm, dataset),\n",
    "    ours=test_3d_on_classes_sampling_pattern(w, model_igs, dataset),\n",
    "    full=test_3d_on_classes_sampling_pattern(fm, model, dataset),\n",
    ")\n",
    "\n",
    "class_map = {0: 'RV cavity', 1: 'LV myo', 2: 'LV cavity'}\n",
    "for name in dice_class_scores.keys():\n",
    "    arr = np.array(dice_class_scores[name]).T\n",
    "    print('##############', name, '##############')\n",
    "    print(pd.DataFrame.from_dict({class_map[i]:arr[i] for i in range(arr.shape[0])}).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
